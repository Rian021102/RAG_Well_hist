{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "loader = TextLoader(\"/Users/rianrachmanto/miniforge3/project/RAG_Drill_Report/data/remark.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=30)\n",
    "documents = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 129/129 [00:17<00:00,  7.41it/s]\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.from_documents(documents, OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True))\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all the problem during drilling?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 40.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the drilling report, the following problems were encountered during drilling:\n",
      "\n",
      "1. Continued slip and cut.\n",
      "2. Troubleshoot issue with stuck lock pin on dead line anchor.\n",
      "3. Slip and cut drill line.\n",
      "4. Hung off block.\n",
      "5. Trouble shot communication to tractor (Production Electronics Cartridge)\n",
      "6. Trouble shot communication to tractor (Production Electronics Cartridge)\n",
      "7. High current observed on tractor during RIH from 4400m to 4570m.\n",
      "\n",
      "Note that these problems were either reported or encountered during the drilling operation, and may not be an exhaustive list of all potential issues.\n"
     ]
    }
   ],
   "source": [
    "# Set up the local model:\n",
    "local_model = \"llama3.1\"\n",
    "llm = ChatOllama(model=local_model, num_predict=400,\n",
    "                 stop=[\"<|start_header_id|>\", \"<|end_header_id|>\", \"<|eot_id|>\"])\n",
    "\n",
    "# Set up the RAG chain:\n",
    "prompt_template = \"\"\"\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "You are a drilling engineer and an analyst. Your task is reading the drilling report,\n",
    "withing the context of the drilling report, answer the question based on the context of the document.\n",
    "All you need to answer what you can find in the document. If you can't find the answer, you can say \"I don't know\".\n",
    "Question: {question}\n",
    "Context: {context}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Querying the LLM (oviously to test here you must ask a relevant question of your data)\n",
    "question = \"List all the problem during drilling?\"\n",
    "print(question)\n",
    "print(rag_chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
